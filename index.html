<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="iLRM: An Iterative Large 3D Reconstruction Model.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>iLRM</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<body>
  <div class="header-wrapper">
    <div class="header-container" id="header-container">
      <div class="header-content">
        <h1 style="font-family: 'CookieRun', serif; font-size: 5rem; font-weight: bold; margin-bottom: 0.1rem;">
          <!-- <span style="color: rgb(217, 160, 116);">i</span><span style="color: rgb(250, 213, 103);">L</span><span style="color: rgb(167, 200, 135);">R</span><span style="color: rgb(136, 160, 212);">M</span> -->
           <span style="color: rgb(230, 100, 80);">i</span><span style="color: rgb(230, 183, 53);">L</span><span style="color: rgb(117, 160, 85);">R</span><span style="color: rgb(96, 120, 172);">M</span>
        </h1>
        <h1 class="title is-1 publication-title" style="font-weight: bold; margin-bottom: 0.5rem; color: rgb(35, 33, 30);">An Iterative Large 3D Reconstruction Model</h1>        
        <!-- <div class="responsive-header" style="font-family: 'Google Sans', sans-serif; font-weight: bold; font-size: 3rem; margin-bottom: 1rem;">
            <h2>An Iterative Large 3D Reconstruction Model</h2>
        </div>         -->
        <!-- <h1 class="title is-1 publication-title" style="font-family: 'CookieRun', serif; font-size: 5rem; margin-top: 1rem;">iLRM</h1> -->
        <!-- <h1 class="title is-1 publication-title" style="font-weight: bold;">An Iterative Large 3D Reconstruction Model</h1> -->
        <div class="is-size-5 publication-authors" style="margin-bottom: 1rem;">
          <a href="https://gynjn.github.io/info/">Gyeongjin Kang</a><sup style="color: black;">1</sup><span style="color: black;">,</span>
          <a href="https://github.com/stnamjef">Seungtae Nam</a><sup style="color: black;">2</sup><span style="color: black;">,</span>
          <a href="https://scholar.google.com/citations?user=VLzxTrAAAAAJ&hl=ko&oi=ao">Xiangyu Sun</a><sup style="color: black;">1</sup><span style="color: black;">,</span>
          <a href="https://www.samehkhamis.com">Sameh Khamis</a><sup style="color: black;">3</sup><span style="color: black;">,</span>
          <a href="https://www.cs.toronto.edu/~asamir/">Abdelrahman Mohamed</a><sup style="color: black;">3</sup><span style="color: black;">,</span>
          <a href="https://silverbottlep.github.io/index.html">Eunbyung Park</a><sup style="color: black;">2</sup>
        </div>
        <div class="is-size-5 publication-authors" style="margin-bottom: 1rem;">
          <span class="author-block" style="color: black;"><sup>1</sup>Sungkyunkwan University,</span>
          <span class="author-block" style="color: black;"><sup>2</sup>Yonsei University,</span>
          <span class="author-block" style="color: black;"><sup>3</sup>Rembrand</span>
        </div>
        <div class="publication-links" style="margin-bottom: -1rem;">
          <!-- PDF Link. -->
          <span class="link-block">
            <a href="https://arxiv.org/pdf/2411.17190"
                class="external-link button is-normal is-dark">
              <span class="icon">
                  <i class="fas fa-file-pdf"></i>
              </span>
              <span>Paper</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://arxiv.org/abs/2411.17190"
                class="external-link button is-normal is-dark">
              <span class="icon">
                  <i class="ai ai-arxiv"></i>
              </span>
              <span>arXiv</span>
            </a>
          </span>
          <!-- Code Link. -->
          <span class="link-block">
            <a href="https://github.com/Gynjn/iLRM"
                class="external-link button is-normal is-dark">
              <span class="icon">
                  <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
              </a>
          </span>
        </div>                 
      </div> 
      <div class="header-video">
          <img draggable="false" src="static/video/tiger.mp4">
      </div>            
    </div>  
  </div>


<section class="hero teaser">
  <div class="container is-max-desktop" style="margin-top: 2rem;">
    <div class="hero-body">
      <img src="static/images/teaser_c.jpg" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px; margin-bottom: -10px">
        <b>iLRM Overview.</b> <br>
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Explanation Video</h2> -->
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/-qSpDZPNIKU"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Feed-forward 3D modeling has emerged as a promising approach for rapid and high-quality 3D reconstruction.
            In particular, directly generating explicit 3D representations, such as 3D Gaussian splatting, 
            has attracted significant attention due to its fast and high-quality rendering, as well as numerous applications.
            However, many state-of-the-art methods, primarily based on transformer architectures, 
            suffer from severe scalability issues because they rely on full attention across image tokens from multiple input views, 
            resulting in prohibitive computational costs as the number of views or image resolution increases.
          </p>
          <p>
            Toward a scalable and efficient feed-forward 3D reconstruction, 
            we introduce an iterative Large 3D Reconstruction Model (<b><i>iLRM</i></b>) 
            that generates 3D Gaussian representations through an iterative refinement mechanism, 
            guided by three core principles: 
            (1) decoupling the scene representation from input-view images to enable <b><i>compact 3D representations</i></b>; 
            (2) decomposing fully-attentional multi-view interactions into a <b><i>two-stage attention</i></b> scheme to reduce computational costs; 
            and (3) injecting <b><i>high-resolution information at every layer</i></b> to achieve high-fidelity reconstruction.
            Experimental results on widely used datasets, such as RE10K and DL3DV, demonstrate that <b><i>iLRM</i></b> outperforms existing methods in both reconstruction quality and speed.            
          </p>
          <p>
            Notably, <b><i>iLRM</i></b> exhibits superior scalability, 
            delivering significantly higher reconstruction quality under comparable computational cost by efficiently leveraging a larger number of input views.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" data-slides-to-show="2">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/flower.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/buda.mp4"
                    type="video/mp4">
          </video>
        </div>        
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/table.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/stone.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/wedding.mp4"
                    type="video/mp4">
          </video>
        </div>        
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/building.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="has-text-centered">
        <p class="subtitle is-5">Results on the DL3DV dataset using 32 input images with a resolution of 512Ã—960.</p>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Core architectural design</h2>
        <img src="static/images/eff_attn_c.jpg" class="center">

        <div class="content has-text-justified">
          <p>
            Our method decouples scene representation from input-view images, 
            enabling efficient computation and compact 3D reconstruction. 
            The example above uses half-resolution views, 
            significantly reducing the attention cost while maintaining high-quality reconstruction.
          </p>
        </div>
      </div>
    </div>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4">12 input images with 512x960 resolution (100 frames)</h3>
        <div class="content has-text-justified">
          <p>
            We compare our method with the state-of-the-art methods on the DL3DV dataset.
            Both methods utilize 12 input images with a resolution of 512x960. 
            We also show the encoding time and memory consumption of each method.
            <b>Note that, our method generates only 1/4 Gaussians compared to the baseline method.</b>
          </p>
        </div>
        <div class="content has-text-centered">
          <div class="video-slider-container">
            <div class="video-slider-wrapper">
              <video id="video-left" autoplay muted loop playsinline>
                <source src="static/video/ours_slider_c.mp4" type="video/mp4">
              </video>
              <video id="video-right" autoplay muted loop playsinline>
                <source src="static/video/ds_slider_c.mp4" type="video/mp4">
              </video>
              <div id="slider-bar"></div>
              <div id="slider-handle"></div>    
              <div class="video-label video-label-left">iLRM (Ours)</div>
              <div class="video-label video-label-right">DepthSplat</div>    
              <!-- ðŸŸ¡ Play/Pause Button -->
              <button id="toggle-play" class="video-toggle-button">
              <img id="toggle-icon" src="static/images/pause.png" alt="Pause" />
              </button>
            </div>    
          </div>          
          <img src="static/images/hr_table.jpg" class="center" style="width: 80%">          
        </div>

        <h3 class="title is-4">24 input images with 256x448 resolution (All frames)</h3>
        <div class="content has-text-justified">
          <p>
            We compare our method with the state-of-the-art methods on the DL3DV dataset.
            Both methods utilize 24 input images with a resolution of 256x448.
            We also show the encoding time and memory consumption of each method.
            <b>Note that, our method generates only 1/4 Gaussians compared to the baseline method.</b>
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="80%">
            <source src="./static/select_first/lr_cc.mp4"
                    type="video/mp4">
          </video>
          <img src="static/images/lr_table.jpg" class="center" style="width: 80%">          
        </div>
        <h3 class="title is-4">Various number of input images on the RE10K dataset</h3>
        <div class="content has-text-justified">
          <p>
            We compare our method with the state-of-the-art methods on the RealEstate10K dataset with various numbers of input images.
          </p>
          <img src="static/images/re10k_page.jpg" class="center">   
          <video id="replay-video"
                 controls
                 muted
                 preload
                 autoplay
                 loop
                 playsinline>
            <source src="./static/video/re10k_page_30.mp4"
                    type="video/mp4">
          </video>          
        </div>        
      </div>
    </div>
  </div>
</section>


<script>
  window.addEventListener("DOMContentLoaded", () => {
    const sliderBar = document.getElementById('slider-bar');
    const videoRight = document.getElementById('video-right');
    const videoLeft = document.getElementById('video-left');
    const wrapper = document.querySelector('.video-slider-wrapper');
    const sliderHandle = document.getElementById('slider-handle');
    
    wrapper.addEventListener('mousemove', (e) => {
      const bounds = wrapper.getBoundingClientRect();
      const offsetX = e.clientX - bounds.left;
      const percent = offsetX / bounds.width;
      const clipPercent = Math.min(100, Math.max(0, percent * 100));
      videoRight.style.clipPath = `inset(0 0 0 ${clipPercent}%)`;
      sliderBar.style.left = `${clipPercent}%`;
      sliderHandle.style.left = `${clipPercent}%`;
    });

    wrapper.addEventListener('mouseleave', () => {
      videoRight.style.clipPath = `inset(0 0 0 50%)`;
      sliderBar.style.left = `50%`;
      sliderHandle.style.left = `50%`;
    });

    // â–¶ï¸ Pause/Play toggle
    const toggleBtn = document.getElementById("toggle-play");
    const icon = document.getElementById("toggle-icon");
    let isPlaying = true;

    toggleBtn.addEventListener("click", () => {
      if (isPlaying) {
        videoLeft.pause();
        videoRight.pause();
        icon.src = "static/images/play.png";
        icon.alt = "Play";
      } else {
        videoLeft.play();
        videoRight.play();
        icon.src = "static/images/pause.png";
        icon.alt = "Pause";
      }
      isPlaying = !isPlaying;
    });
  });
</script>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
      <pre><code style="font-size: 1.25em;">@article{GenerativeDensification,
    title={Generative Densification: Learning to Densify Gaussians for High-Fidelity Generalizable 3D Reconstruction}, 
    author={Nam, Seungtae and Sun, Xiangyu and Kang, Gyeongjin and Lee, Younggeun and Oh, Seungjun and Park, Eunbyung},
    journal={arXiv preprint arXiv:2412.06234},
    year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2411.17190">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Gynjn" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> 
            which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
